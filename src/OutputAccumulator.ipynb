{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import shutil\n",
    "from random import randint\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from skimage import io, color, exposure\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_preds='backup/SpatialVideoPreds'\n",
    "opf_preds = 'backup/MotionVideoPreds'\n",
    "\n",
    "with open(rgb_preds,'rb') as f:\n",
    "    rgb =pickle.load(f)\n",
    "f.close()\n",
    "with open(opf_preds,'rb') as f:\n",
    "    opf =pickle.load(f)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplitter():\n",
    "    def __init__(self, path = 'Data/'):\n",
    "        self.path = path\n",
    "        self.actionLabel={}\n",
    "        with open(self.path+'classInd.txt') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.strip('\\r\\n') for line in lines]\n",
    "        f.close()\n",
    "        for line in lines:\n",
    "            label,action = line.split(' ')\n",
    "            if action not in self.actionLabel.keys():\n",
    "                self.actionLabel[action]=label\n",
    "\n",
    "    def splitTestTrain(self):\n",
    "        self.trainVideo = self.file2_dic(self.path+'trainlist.txt')\n",
    "        self.testVideo = self.file2_dic(self.path+'testlist.txt')\n",
    "        print('number of train and test videos', len(self.trainVideo),len(self.testVideo))\n",
    "        return self.trainVideo, self.testVideo\n",
    "\n",
    "    def file2_dic(self,fname):\n",
    "        with open(fname) as f:\n",
    "            lines = f.readlines()\n",
    "            content = [line.strip('\\r\\n') for line in lines]\n",
    "        f.close()\n",
    "        dic={}\n",
    "        for line in lines:\n",
    "            video = line.split('/',1)[1].split(' ',1)[0]   # v_ApplyEyeMakeup_g01_c03.avi\n",
    "            key = video.split('_',1)[1].split('.',1)[0]    # ['v', 'ApplyEyeMakeup_g01_c03.avi'], ['ApplyEyeMakeup_g01_c03', 'avi']\n",
    "            label = self.actionLabel[line.split('/')[0]]   # 1\n",
    "            dic[key] = int(label)\n",
    "        return dic\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     splitter = DataSplitter()\n",
    "#     train_video,test_video = splitter.splitTestTrain()\n",
    "#     print(len(train_video),len(test_video))  # ApplyEyeMakeup_g08_c01': 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spatialDataset(Dataset):  \n",
    "    def __init__(self, dic, rootDir= \"Data/\", mode = 'train', transform=None):\n",
    "        self.keys = list(dic.keys())   # name of videos\n",
    "        self.values = list(dic.values())   # number of frames - 10\n",
    "        self.rootDir = rootDir+\"jpegs_256/\"\n",
    "        self.mode =mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def loadImage(self,videoName, index):\n",
    "        path = self.rootDir + 'v_'+videoName+'/'\n",
    "        try:\n",
    "            img = Image.open(path + 'frame' +str(index).zfill(6)+'.jpg')\n",
    "        except:\n",
    "            n = 1\n",
    "            tempPath = path + 'frame' +str(index).zfill(6)+'.jpg'\n",
    "            while not os.path.exists(tempPath):\n",
    "                tempPath = path + 'frame' +str(index+n).zfill(6)+'.jpg'\n",
    "                if n>0:\n",
    "                    n= -1*n\n",
    "                else:\n",
    "                    n = -1*n +1\n",
    "            img = Image.open(tempPath)\n",
    "        transformed_img = self.transform(img)\n",
    "        img.close()\n",
    "        return transformed_img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            videoName, nb_clips = self.keys[idx].split(' ')\n",
    "            nb_clips = int(nb_clips)\n",
    "            clips = []\n",
    "            clips.append(random.randint(1, nb_clips//3))\n",
    "            clips.append(random.randint(nb_clips//3, nb_clips*2//3))\n",
    "            clips.append(random.randint(nb_clips*2//3, nb_clips+1))    # take three random frame from 3-halves of video\n",
    "        elif self.mode == 'val':\n",
    "            videoName, index = self.keys[idx].split(' ')\n",
    "            frameIndex =abs(int(index))\n",
    "        label = self.values[idx]\n",
    "        label = int(label)-1\n",
    "        if self.mode=='train':\n",
    "            data ={}\n",
    "            for i in range(len(clips)):\n",
    "                key = 'img'+str(i)\n",
    "                index = clips[i]\n",
    "                data[key] = self.loadImage(videoName, index)    # img1 : IMAGE_DATA\n",
    "            sample = (data, label)  # (3 frames , label)\n",
    "        elif self.mode=='val':\n",
    "            data = self.loadImage(videoName,frameIndex)\n",
    "            sample = (videoName, data, label)   #  ApplyEyeMakeup_g08_c01 , IMAGE_DATA , label\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spatialDataloader():\n",
    "    def __init__(self, dataSplitter, batchSize = 8, numWorkers=4, path = 'Data/'):\n",
    "        self.batchSize=batchSize\n",
    "        self.numWorkers=numWorkers\n",
    "        self.dataPath=path\n",
    "        self.frameCount ={}\n",
    "        self.trainVideo, self.testVideo = dataSplitter.splitTestTrain()\n",
    "        with open(self.dataPath+'frame_count.pickle','rb') as file:\n",
    "            dicFrame = pickle.load(file)\n",
    "        file.close()\n",
    "        for line in dicFrame :\n",
    "            videoname = line.split('_',1)[1].split('.',1)[0]\n",
    "            self.frameCount[videoname]=dicFrame[line]\n",
    "\n",
    "    def getData(self):\n",
    "        trainLoader = self.getTrainLoader()\n",
    "        valLoader = self.getValLoader()\n",
    "        return trainLoader, valLoader, self.testVideo\n",
    "\n",
    "\n",
    "    def getTrainLoader(self):\n",
    "        self.dic_training={}\n",
    "        for video in self.trainVideo:  # ApplyEyeMakeup_g08_c01': 1 \n",
    "            nFrame = self.frameCount[video]-10+1\n",
    "            key = video+' '+ str(nFrame)\n",
    "            self.dic_training[key] = self.trainVideo[video]    # ApplyEyeMakeup_g08_c01 NUNBER_OF_FRAMES : 1\n",
    "            \n",
    "        transform = transforms.Compose([\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "        training_set = spatialDataset(dic=self.dic_training, mode='train', transform= transform)\n",
    "        print('==> Training data :',len(training_set),'frames')\n",
    "        print(training_set[1][0]['img1'].size())\n",
    "\n",
    "        trainLoader = DataLoader(\n",
    "            dataset=training_set, \n",
    "            batch_size=self.batchSize,\n",
    "            shuffle=True,\n",
    "            num_workers=self.numWorkers)\n",
    "        return trainLoader\n",
    "\n",
    "    def getValLoader(self):\n",
    "        # for each video extract 19 frames and send it with label\n",
    "        self.dic_testing={}\n",
    "        for video in self.testVideo:  # ApplyEyeMakeup_g08_c01': 1\n",
    "            nFrame = self.frameCount[video]-10+1\n",
    "            interval = nFrame//19\n",
    "            for i in range(19):\n",
    "                key = video+' '+str(i*interval+1)\n",
    "                self.dic_testing[key] = self.testVideo[video]  # ApplyEyeMakeup_g08_c01 FRAME_NUMBER : 1\n",
    "                \n",
    "        transform = transforms.Compose([\n",
    "                transforms.Resize([224,224]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "        validation_set = spatialDataset(dic=self.dic_testing, mode='val', transform= transform)\n",
    "        print('==> Validation data :',len(validation_set),'frames')\n",
    "        valLoader = DataLoader(\n",
    "            dataset=validation_set, \n",
    "            batch_size=self.batchSize, \n",
    "            shuffle=False,\n",
    "            num_workers=self.numWorkers)\n",
    "        return valLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     dataloader = spatialDataloader(splitter)\n",
    "#     trainLoader,valLoader,test_video = dataloader.getData()\n",
    "#     print(len(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batchSize = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batchSize))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train and test videos 985 389\n",
      "==> Training data : 985 frames\n",
      "torch.Size([3, 224, 224])\n",
      "==> Validation data : 7391 frames\n",
      "tensor(92.8021) tensor(98.9717)\n"
     ]
    }
   ],
   "source": [
    "splitter = DataSplitter()\n",
    "dataloader = spatialDataloader(splitter)\n",
    "_,_,testVideo = dataloader.getData()\n",
    "\n",
    "overallPreds = np.zeros((len(rgb.keys()),10))\n",
    "labels = np.zeros(len(rgb.keys()))\n",
    "correct=0\n",
    "index=0\n",
    "for name in sorted(rgb.keys()):   \n",
    "    r = rgb[name]\n",
    "    o = opf[name]\n",
    "    label = int(testVideo[name])-1\n",
    "\n",
    "    overallPreds[index,:] = (r+o)\n",
    "    labels[index] = label\n",
    "    index+=1         \n",
    "    if np.argmax(r+o) == (label):\n",
    "        correct+=1\n",
    "\n",
    "labels = torch.from_numpy(labels).long()\n",
    "overallPreds = torch.from_numpy(overallPreds).float()\n",
    "\n",
    "top1,top5 = accuracy(overallPreds, labels, topk=(1,5))     \n",
    "\n",
    "print(top1,top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
